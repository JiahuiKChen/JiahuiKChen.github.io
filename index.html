---
layout: page
title: Jiahui (Karen) Chen
subtitle: AI Researcher 
show-avatar: true
---
<br>
<br>
Hey there!
<br>
I'm a PhD student at UT Austin, advised by Amy Zhang, and an 
<a href="https://www.nsf.gov/cise/CSGrad4US/"> NSF CSGrad4US Fellow</a>. 
During my PhD, I've spent a lot of time at Meta Fundamental AI Research (FAIR) working on multimodal generative models.
<br>
<br>
My research focuses on unified models that jointly generate text and images, along with designing effective rewards and datasets for multimodal training.
<br>
Previously I was an engineer at Meta working on various machine learning projects, including Meta's first generative AI product: 
<a href="https://www.theverge.com/2023/9/27/23892231/meta-generative-ai-image-editing-stickers-instagram-facebook-whatsapp"> AI-generated stickers</a>.

<br>
<br>
<br>
<!-- News section -->
<h2 class="post-title">
  News & Updates:
</h2>

<!-- Div for all entries, Each entry gets own article -->
<!-- Example usage of jekyll's paginator: https://github.com/sjackman/sjackman.github.io/blob/master/index.html -->
<div class="posts-list">

  <!-- Post-training Unified Text-Image Generation Paper -->
  <article class="post-preview">
    <a href="https://arxiv.org/abs/2601.04339">
    <h3 class="post-subtitle">
      New Paper: Unified Text-Image Generation with Weakness-Targeted Post-Training
    </h3>
    </a>
    <p class="post-entry">
      We post-train multimodal models to unify text and image generation in a single inference call, enabling the model to automatically transition between reasoning about an image and generating it.
      Our weakness-targeted synthetic dataset and reward function analysis leads to significant text-to-image performance improvements over the base model.
    </p>
    <!-- date -->
    <p class="post-meta">
      January, 2026
    </p>
  </article>

  <!-- MLLM Evaluator paper -->
  <article class="post-preview">
    <a href="https://arxiv.org/abs/2505.00759">
    <h3 class="post-subtitle">
      New Paper: Multi-Modal Language Models as Text-to-Image Model Evaluators
    </h3>
    </a>
    <p class="post-entry">
      We present a text-to-Image (T2I) model evaluation method leveraging vision-language models as evaluator agents that generate image prompts and judge generated images. 
      Our methodâ€™s T2I model rankings match existing benchmarks' rankings while using 80x less prompts and achieves higher correlations with human judgments.
    </p>
    <!-- date -->
    <p class="post-meta">
      April, 2025
    </p>
  </article>

  <!-- Gen AI Stickers Paper -->
  <article class="post-preview">
    <a href="https://arxiv.org/abs/2311.10794">
    <h3 class="post-subtitle">
      "Text-to-Sticker: Style Tailoring Latent Diffusion Models for Human Expression" accepted at ECCV 2024
    </h3>
    </a>
    <p class="post-entry">
      Paper on the text-to-image foundation model used in various Meta platforms. 
    </p>
    <!-- date -->
    <p class="post-meta">
      July, 2024
    </p>
  </article>
  
  <!-- PhD Start -->
  <article class="post-preview">
    <h3 class="post-subtitle">
      Started PhD at University of Texas at Austin
    </h3>
    <p class="post-entry">
      Advised by Amy Zhang. 
    </p>
    <!-- date -->
    <p class="post-meta">
      August, 2023
    </p>
  </article>
  
  <!-- Joined Gen AI at Meta -->
  <article class="post-preview">
    <h3 class="post-subtitle">
      Joined the Generative AI Team at Meta
    </h3>
    <p class="post-entry">
      Joined the team that founded generative AI efforts at Meta. Working on text to image diffusion models and their product applications.
      The New York Times wrote about our team 
      <a href="https://www.nytimes.com/2023/02/07/technology/meta-artificial-intelligence-chatgpt.html""> here</a>.
    </p>
    <!-- date -->
    <p class="post-meta">
      December, 2022
    </p>
  </article>
  
  <!-- CSGrad4US / NSF Fellowship -->
  <!-- <article class="post-preview"> -->
    <!-- <a href="https://cra.org/csgrad4us/#tab-id-3"> -->
    <!-- <h3 class="post-subtitle"> -->
      <!-- Received NSF's CSGrad4US Graduate Fellowship -->
    <!-- </h3> -->
    <!-- </a> -->
    <!-- <p class="post-entry"> -->
      <!-- Provides funding for a PhD in the Computer and Information Sciences.  -->
      <!-- I will be applying for PhD programs in the 2022 fall application cycle.   -->
    <!-- </p> -->
    <!-- date -->
    <!-- <p class="post-meta"> -->
      <!-- August 10, 2022 -->
    <!-- </p> -->
  <!-- </article> -->
  
  <!-- [NOT SHOWN] WiML 2021 Label Noise Poster --> 
<!--   <article class="post-preview">
    <a href="https://sites.google.com/view/wiml2021/program">
    <h3 class="post-subtitle">
      Poster on Robust Model Performance in the Presence of Noisy Labels 
      in the Women in Machine Learning 2021 Conference 
    </h3>
    </a>
    <p class="post-entry">
      Using the uncertainty quantification technique Monte Carlo Dropout helps maintain model performance even 
      when a notable portion of training labels are incorrect. 
      Poster PDF available 
      <a href="https://drive.google.com/file/d/1p2IxrBZI2JPNt77GsGPNlE6Q13tJEPNm/view"> here</a>. 
      Collaborative work from the Probabilistic Neural Networks team. 
    </p>
    <!-- date -->
    <!-- <p class="post-meta"> -->
<!--       December 9, 2021 -->
    <!-- </p> -->
  <!-- </article>  -->

  <!-- UNDERGRAD THESIS PUB -->
  <article class="post-preview">
    <a href="http://link.springer.com/article/10.1007/s10586-021-03393-2">
    <h3 class="post-subtitle">
      "Practical and Configurable Network Traffic Classification Using Probabilistic Machine Learning"
      published in Springer Nature's Cluster Computing 2021
    </h3>
    </a>
    <p class="post-entry">
      My undergraduate thesis, PDF available <a href="https://arxiv.org/abs/2107.06080"> here</a>.
    </p>
    <!-- date -->
    <p class="post-meta">
      September 16, 2021
    </p>
  </article>

  <!-- Joined Probability: Probabilistic Neural Netowrks @ FB -->
  <!-- <article class="post-preview"> -->
    <!-- <h3 class="post-subtitle"> -->
      <!-- Joined the Probabilistic Neural Netowrks team at Facebook Research  -->
    <!-- </h3> -->
    <!-- <p class="post-entry"> -->
      <!-- Working on research and infrastructure for -->
      <!-- uncertainty quantification in deep learning. -->
    <!-- </p> -->
    <!-- date -->
    <!-- <p class="post-meta"> -->
      <!-- July 27, 2020 -->
    <!-- </p> -->
  <!-- </article> -->

  <!-- [NOT SHOWN] Graduation -->
<!--   <article class="post-preview">
    <h3 class="post-subtitle">
      Graduated Cum Laude with a Computer Science B.S. and minors in Math and Cognitive Science,
      from the University of Utah.
    </h3>
    <!-- date -->
    <!-- <p class="post-meta"> -->
<!--      May 1, 2020 -->
    <!-- </p> -->
    <!-- <div class="post-entry">
      {{ post.content | strip_html | xml_escape | truncatewords: 50 }}
    <a href="{{ post.url | prepend: site.baseurl }}" class="post-read-more">[Read&nbsp;More]</a> -->
  <!-- </article>  -->

</div>
